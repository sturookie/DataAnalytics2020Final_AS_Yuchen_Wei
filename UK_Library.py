# -*- coding: utf-8 -*-
"""Library.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iCzzCEYWzt5NtEHZgELU41yWLBbCPTnD
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

Library_and_GAV = pd.read_csv('/content/drive/My Drive/UK_Library/Libraries_and_GAV.csv')
EDA = pd.read_csv('/content/drive/My Drive/UK_Library/EDA.csv')
train = pd.read_csv('/content/drive/My Drive/UK_Library/Libraries_and_indicators.csv')
test = pd.read_csv('/content/drive/My Drive/UK_Library/Libraries_test.csv')

EDA.columns

fig = px.scatter(Library_and_GAV, x="Location", y="GVA of City(billion)",marginal_y="box")
fig.show()

fig3 = px.scatter(Library_and_GAV, x="Location", y = "Number of Libraries",marginal_y="box")
fig3.show()

drop_london = Library_and_GAV.drop(Library_and_GAV[Library_and_GAV['Location'] == 'Greater London'].index)
fig4 = px.bar(drop_london,drop_london['Location'],drop_london['GVA of City(billion)'], hover_name='Location',hover_data=['Location'],color='Location',title='GVA of different region.')
fig4.show()

drop_billon = Library_and_GAV

px.scatter_matrix(Library_and_GAV)

fig2 = px.scatter(EDA, x="Location", y="Number of Libraries")
fig2.show()

#Model 1 is LinearRegression
from sklearn.linear_model import LinearRegression

X = Library_and_GAV[['GVA of City(billion)','Number of Libraries']]
y = Library_and_GAV['GVA of City(billion)']
reg = LinearRegression().fit(X, y)
print(reg.score(X, y))
print(reg.coef_)
print(reg.intercept_)

print(train.columns)
print(test.columns)

from sklearn.model_selection import train_test_split

X = train [[ 'Number of Libraries', 'GVA of City(billion)','Average salary']]
y = train['Satisfaction']
train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=100)

#Model 2 is K- Nearest Neighbors
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
classifier = KNeighborsClassifier(n_neighbors=10, algorithm= 'kd_tree')
classifier.fit(train_X, train_y)

#The Lancashire was selected to compare with the Test dataset to test the accuracy of model predictions.

test_value = test[0:1] 
test_val = test_value[[ 'Number of Libraries', 'GVA of City(billion)','Average salary']]
print(test_value)

knn0_predict_y = classifier.predict(test_val)

knn0_train_y = classifier.predict(train_X)                         ##Using whole dataset to predict.
knn0_test_y = classifier.predict(test_X)
knn0_train_accuracy = metrics.accuracy_score(train_y, knn0_train_y)
knn0_test_accuracy = metrics.accuracy_score(test_y, knn0_test_y)
knn0_test_mse = metrics.mean_squared_error(test_y,knn0_test_y)
print("The predicting Satisfaction of Lancashire is", int(knn0_predict_y))
print("The true Satisfaction of Lancashire is", train.at[0,'Satisfaction'])
print("The Mean Squared Error of K- Nearest Neighbors model is ",knn0_test_mse)

#Model 3 is Gaussian Naive Bayes
from sklearn.naive_bayes import GaussianNB

bay_model = GaussianNB()
bay_model.fit(train_X,train_y)

#The Lancashire was selected to compare with the Test dataset to test the accuracy of model predictions.
bay_predict_y = bay_model.predict(test_val)

bay_train_y = bay_model.predict(train_X)                     ##Using whole dataset to predict.
bay_test_y = bay_model.predict(test_X)
bay_train_accuracy = metrics.accuracy_score(train_y, bay_train_y)
bay_test_accuracy = metrics.accuracy_score(test_y, bay_test_y)
bay_test_mse = metrics.mean_squared_error(test_y,bay_test_y)
print("The predicting Satisfaction of Lancashire is", int(bay_predict_y))
print("The true Satisfaction of Lancashire is", train.at[0,'Satisfaction'])
print("The Mean Squared Error of Naive Bayes model is ",bay_test_mse)

#Model 4 is RandomForest
from sklearn.ensemble import RandomForestClassifier

ran_model = RandomForestClassifier(n_estimators = 50,criterion='entropy', max_features='auto')
ran_model.fit(train_X,train_y)

#The Lancashire was selected to compare with the Test dataset to test the accuracy of model predictions.
ran_predict_y = ran_model.predict(test_val)

ran_train_y = ran_model.predict(train_X)                     ##Using whole dataset to predict.
ran_test_y = ran_model.predict(test_X)
ran_train_accuracy = metrics.accuracy_score(train_y, ran_train_y)
ran_test_accuracy = metrics.accuracy_score(test_y, ran_test_y)
ran_test_mse = metrics.mean_squared_error(test_y,ran_test_y)
print("The predicting Satisfaction of Lancashire is", int(ran_predict_y))
print("The true Satisfaction of Lancashire is", train.at[0,'Satisfaction'])
print("The Mean Squared Error of Random Forest model is ",ran_test_mse)